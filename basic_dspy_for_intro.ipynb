{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/miniconda3/envs/dspy/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20, 50)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dspy.datasets import HotPotQA\n",
    "\n",
    "# Load the dataset.\n",
    "dataset = HotPotQA(train_seed=1, train_size=20, eval_seed=2023, dev_size=50, test_size=0)\n",
    "\n",
    "# Tell DSPy that the 'question' field is the input. Any other fields are labels and/or metadata.\n",
    "trainset = [x.with_inputs('question') for x in dataset.train]\n",
    "devset = [x.with_inputs('question') for x in dataset.dev]\n",
    "\n",
    "len(trainset), len(devset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('question',\n",
       "  'At My Window was released by which American singer-songwriter?'),\n",
       " ('answer', 'John Townes Van Zandt')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.train[0].items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Ollama\n",
    "- Use the `Ollamalocal` in the dspy to interact with ollama model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_model = dspy.OllamaLocal(\n",
    "    model='phi3',\n",
    "    model_type='text',\n",
    "    max_tokens=350,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    frequency_penalty=1.17,\n",
    "    top_k=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" Pluto, being a dwarf planet located in our solar system's Kuiper Belt, experiences extremely harsh and cold conditions. Its atmosphere is very thin compared to Earth's and mostly composed of nitrogen (N2), with traces of methane (CH4) and carbon monoxide (CO).\\n\\nThe weather on Pluto varies significantly due to its elliptical orbit around the Sun, which takes about 248 Earth years. During aphelion when it is farthest from the Sun, temperatures can drop as low as approximately -375 degrees Fahrenheit (-225 Celsius). This makes Pluto one of the coldest objects in our solar system.\\n\\nHowever, there are some interesting atmospheric phenomena on Pluto caused by its complex interactions with sunlight and moon Charon. Whenever Pluto moves closer to the Sun during its orbit (perihelion), it experiences a slight warming effect which can cause seasonal changes in temperature and possibly affect surface ice sublimation, contributing to atmospheric density variations as well.\\n\\nThe New Horizons spacecraft flew by Pluto on July 14th, 2015, providing us with valuable data about its atmosphere and weather patterns for the first time ever in history. Despite this information being relatively recent due to limited observations so far, it has allowed scientists to gain insight into the unique conditions present within our solar system's fringes.\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama_model(\"Tell me about the weather on pluto?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure LLM \n",
    "- In order to use the ollama model, set the DsPy settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.settings.configure(lm=ollama_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `Signature` is more like a `Task` that you want to be performed.\n",
    "- The docstring is like `system` prompt.\n",
    "- For the example below (QA) even the input and the output fields are defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicQA(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define predictor\n",
    "generate_answer = dspy.Predict(BasicQA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    answer=\"Earl Godwin's husband, King Edward the Confessor\"\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "dev_example = devset[4]\n",
    "pred = generate_answer(question=dev_example.question)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Example({'question': 'In the 10th Century A.D. Ealhswith had a son called Æthelweard by which English king?', 'answer': 'King Alfred the Great', 'gold_titles': {'Æthelweard (son of Alfred)', 'Ealhswith'}}) (input_keys={'question'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Answer questions with short factoid answers.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: often between 1 and 5 words.\n",
      "\n",
      "---\n",
      "\n",
      "Question: In the 10th Century A.D. Ealhswith had a son called Æthelweard by which English king?\n",
      "Answer:\u001b[32m Earl Godwin's husband, King Edward the Confessor\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nAnswer questions with short factoid answers.\\n\\n---\\n\\nFollow the following format.\\n\\nQuestion: ${question}\\nAnswer: often between 1 and 5 words.\\n\\n---\\n\\nQuestion: In the 10th Century A.D. Ealhswith had a son called Æthelweard by which English king?\\nAnswer:\\x1b[32m Earl Godwin's husband, King Edward the Confessor\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama_model.inspect_history(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
